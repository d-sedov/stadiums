{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "#\n",
    "# FILE: stadium_matching.ipynb\n",
    "#\n",
    "# BY: Timur Abbiasov\n",
    "#\n",
    "# DATE: Aug 25 2020\n",
    "#\n",
    "# DESC: This code contains three parts: \n",
    "# (1) first, I match subsidies data from Long 2013 to the main stadiums table\n",
    "# (2) second, I match the data on stadium capacity from Wikipedi to the main stadiums table\n",
    "# (3) finally, I use the matched data to conduct cost-benefit analysis of stadium subsidies using a number of assumptions\n",
    "#\n",
    "# COMMENT: \n",
    "#\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Libraries #####################################\n",
    "\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Options and definitions #####################################\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def flatten(l):\n",
    "  out = []\n",
    "  for item in l:\n",
    "    if isinstance(item, (list, tuple)):\n",
    "      out.extend(flatten(item))\n",
    "    else:\n",
    "      out.append(item)\n",
    "  return out\n",
    "\n",
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return x.quantile(n)\n",
    "    percentile_.__name__ = 'percentile_{:2.0f}'.format(n*100)\n",
    "    return percentile_\n",
    "\n",
    "leagueBySport = {'hockey': 'NHL', 'football': 'NFL', 'baseball': 'MLB', 'basketball': 'NBA'} \n",
    "\n",
    "################################ Env variables #####################################\n",
    "\n",
    "load_dotenv()\n",
    "PSQL_USER = os.getenv('PSQL_USER')\n",
    "PSQL_PASS = os.getenv('PSQL_PASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "####################### Part I: Subsidy Matching ###############################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stadiums():\n",
    "    \"\"\"Read in the stadiums data.\"\"\"\n",
    "    \n",
    "    # PostgreSQL connection\n",
    "    engine = db.create_engine(f'postgresql://{PSQL_USER}:{PSQL_PASS}@134.209.70.145/dataname2')\n",
    "    \n",
    "    # Read stadiums into a dataframe\n",
    "\n",
    "    get_stadiums_table = f\"\"\"\n",
    "            SELECT\n",
    "                sname_place_id as stadium_id,\n",
    "                sport as stadium_sport,\n",
    "                location_name,\n",
    "                city,\n",
    "                cbg as stadium_cbg\n",
    "            FROM\n",
    "                stadiums\n",
    "                ;\n",
    "            \"\"\"\n",
    "    \n",
    "    results = pd.read_sql(get_stadiums_table, con = engine)\n",
    "    engine.dispose()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new table with subsidies using the data from Long 2013\n",
    "\n",
    "subsidies = pd.read_csv(\"./data/subsidies_long_2013.csv\", header = None,\n",
    "                        names = ['year_opened', 'location', \"league\", \"facility_name\",\n",
    "                                  \"total_cost_reported\",\"public_cost_reported\", \n",
    "                                  \"total_cost_2010\", \"public_cost_2010\", \"public_share_pct\"])\n",
    "\n",
    "subsidies['record_index'] = subsidies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new table with stadiums\n",
    "\n",
    "stadiums = get_stadiums()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tables to dictionaries (to be used in the matching procedure)\n",
    "\n",
    "subsidy_records = subsidies[['record_index','location', 'league', 'facility_name']].to_dict('records');\n",
    "stadium_records = stadiums[['stadium_id','location_name', 'city']].to_dict('records');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that returns 'exact matches', \n",
    "# returns true if all words in both stadium name and its location can be found in the corresponding subsidy record:\n",
    "\n",
    "def compare_entries(stadium_record, subsidy_record):\n",
    "    check_location = all((word.lower() in subsidy_record['location'].lower()) for word in stadium_record['city'].split(' '))\n",
    "    check_name = all((word.lower() in subsidy_record['facility_name'].lower()) for word in stadium_record['location_name'].split(' '))\n",
    "    return all([check_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list that associates each stadium record with the list of subsidy records that matches exactly\n",
    "# (using compare_entries)\n",
    "\n",
    "stadium_matching = list(\n",
    "    map(lambda stadium_record: {\n",
    "        stadium_record['stadium_id']: list(\n",
    "            map(lambda x: {**x, 'stadium_id': stadium_record['stadium_id']},\n",
    "                filter(lambda subsidy_record: compare_entries(stadium_record,subsidy_record),subsidy_records)\n",
    "            )\n",
    "        )\n",
    "    },\n",
    "    stadium_records\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sg:1cc8dbe5600542ceba0de4a2f15eb7a6': [{'record_index': 104, 'location': 'New York', 'league': 'NBA/ NHL', 'facility_name': 'Madison Square Garden (R)', 'stadium_id': 'sg:1cc8dbe5600542ceba0de4a2f15eb7a6'}, {'record_index': 150, 'location': 'New York', 'league': 'NBA/ NHL', 'facility_name': 'Madison Square Garden', 'stadium_id': 'sg:1cc8dbe5600542ceba0de4a2f15eb7a6'}, {'record_index': 206, 'location': 'New York', 'league': 'NBA/NHL', 'facility_name': 'Madison Square Garden III', 'stadium_id': 'sg:1cc8dbe5600542ceba0de4a2f15eb7a6'}]}\n"
     ]
    }
   ],
   "source": [
    "print(stadium_matching[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matched data to matched_data table, and save unmatched stadium records separately for further processing\n",
    "\n",
    "unmatched_stadium_ids = list(map(lambda x: list(x.keys())[0], [f for f in stadium_matching if not list(f.values())[0]]))\n",
    "unmatched_stadiums = stadiums[stadiums['stadium_id'].isin(unmatched_stadium_ids)]\n",
    "unmatched_stadiums.reset_index(inplace=True)\n",
    "\n",
    "stadium_matched_records = list(filter(lambda x: list(x.values())[0], stadium_matching))\n",
    "matched_data = pd.DataFrame.from_dict(flatten(map(lambda x: list(x.values()), stadium_matched_records)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions that return best matching subsidy record(s) for a given stadium record,\n",
    "# using nltk edit distance for stadium name to determine similarity\n",
    "\n",
    "def findMatches(stadium_name,start=None,end=None):\n",
    "    sortedResults = sorted(\n",
    "        map(lambda sub: {'facility_name': sub['facility_name'],\n",
    "                         'location': sub['location'],\n",
    "                         'league': sub['league'],\n",
    "                         'record_index': sub['record_index'],\n",
    "                         'best_match_distance': nltk.edit_distance(\n",
    "                             stadium_name.lower().replace('\\n','').replace('/',''),\n",
    "                             sub['facility_name'].lower().replace('\\n','').replace('/','')\n",
    "                         )},\n",
    "            subsidies.to_dict('records'),\n",
    "           ), key = lambda item: item['best_match_distance'], reverse = False\n",
    "    )\n",
    "    return sortedResults[start:end]\n",
    "\n",
    "def findBestMatch(stadium_name):\n",
    "    return findMatches(stadium_name,start = None, end = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = unmatched_stadiums['location_name'].apply(findBestMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = unmatched_stadiums.join(pd.DataFrame.from_records(matches)[['record_index','location','league','facility_name','best_match_distance']])\n",
    "matches['city_distance'] = matches[['city','location']].apply(lambda x: nltk.edit_distance(x[0].lower(),x[1].lower()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_matches_by_city = (\n",
    "    matches[['city_distance','best_match_distance']].apply(min,axis=1) < 4) & (\n",
    "    matches['best_match_distance']*matches['city_distance']<=20)\n",
    "\n",
    "matches_by_city = matched_data.append(\n",
    "    matches[filter_matches_by_city][['record_index','location','league','facility_name','stadium_id']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsidies_matched_v1 = pd.merge(matches_by_city[['record_index','stadium_id']],subsidies, left_on='record_index' ,right_on='record_index', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_unmatched_stadiums = stadiums[~stadiums['stadium_id'].isin(subsidies_matched_v1['stadium_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that return best matching subsidy records for a given stadium record,\n",
    "# using nltk edit distance for both stadium name and city name:\n",
    "# returns all records with the minimum edit distance in city name \n",
    "# and sorts the results by edit ditance in stadium name\n",
    "\n",
    "def findCityMatches(stadium_dict,start=None,end=None):\n",
    "    stadium_id = stadium_dict['stadium_id']\n",
    "    city_name = stadium_dict['city']\n",
    "    stadium_name = stadium_dict['location_name']\n",
    "    stadium_league = leagueBySport[stadium_dict['stadium_sport']]\n",
    "    sortedResults = sorted(\n",
    "        map(lambda sub: {'stadium_id': stadium_id,\n",
    "                         'stadium_name': stadium_name,\n",
    "                         'stadium_city': city_name,\n",
    "                         'stadium_league': stadium_league,\n",
    "                         'sub_name': sub['facility_name'],\n",
    "                         'sub_city': sub['location'],\n",
    "                         'sub_league': sub['league'],\n",
    "                         'record_index': sub['record_index'],\n",
    "                         'best_city_match_distance': nltk.edit_distance(\n",
    "                             city_name.lower().replace('\\n','').replace('/',''),\n",
    "                             sub['location'].lower().replace('\\n','').replace('/','')\n",
    "                         ),\n",
    "                         'best_match_distance': nltk.edit_distance(\n",
    "                             stadium_name.lower().replace('\\n','').replace('/',''),\n",
    "                             sub['facility_name'].lower().replace('\\n','').replace('/','')\n",
    "                         )},\n",
    "            subsidies.to_dict('records'),\n",
    "           ), key = lambda item: item['best_city_match_distance'], reverse = False\n",
    "    )\n",
    "    \n",
    "    minCityMatchDistance = sortedResults[0]['best_city_match_distance']\n",
    "    sortedResultsSimilarCity = sorted(\n",
    "        [sub for sub in sortedResults if (\n",
    "            sub['best_city_match_distance'] <= minCityMatchDistance\n",
    "        ) \n",
    "        & (\n",
    "            stadium_league in sub['sub_league'] \n",
    "        )\n",
    "        ],\n",
    "        key = lambda item: item['best_match_distance'], reverse = False\n",
    "    )\n",
    "    if sortedResultsSimilarCity: \n",
    "        return sortedResultsSimilarCity[start:end]\n",
    "    else:\n",
    "        return [{'stadium_id': stadium_id,\n",
    "                'stadium_name': stadium_name,\n",
    "                'stadium_city': city_name,\n",
    "                'stadium_league': stadium_league,\n",
    "                'best_city_match_distance': None}]\n",
    "    \n",
    "def findBestCityMatch(stadium_dict):\n",
    "    return findCityMatches(stadium_dict ,start = None, end = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findCityMatches({'location_name': 'Enterprise Center',\n",
    "#                  'city': 'saint louis', \n",
    "#                  'stadium_sport': 'hockey', \n",
    "#                  'stadium_id': 'sg:ac283081b6e44c1cb19feb1a5ce6fa5d'\n",
    "#                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain best matches for each unmatched stadium record using findBestCityMatch() \n",
    "\n",
    "city_matches = pd.DataFrame.from_records(\n",
    "    flatten(remaining_unmatched_stadiums[\n",
    "        remaining_unmatched_stadiums['stadium_sport'] != 'soccer'\n",
    "    ][['stadium_id','location_name','city','stadium_sport']].apply(\n",
    "        lambda x: findCityMatches(\n",
    "            dict(zip(['stadium_id','location_name','city','stadium_sport'],x))\n",
    "        ), axis=1\n",
    "    ))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the candidate matches to csv for manual verification\n",
    "\n",
    "city_matches.to_csv(\"./data/tmp/by_location_and_league.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import manually verified matches:\n",
    "\n",
    "manual_matches = pd.read_csv(\"./data/manual-matches/by_location_and_league.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the manual matches to the subsidies data:\n",
    "\n",
    "subsidies_matched_manual = pd.merge(\n",
    "                            manual_matches[manual_matches['match']=='1'][['stadium_id','record_index']],\n",
    "                            subsidies,\n",
    "                            left_on='record_index' ,right_on='record_index', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the previously obtained mathes wih the remaining manual ones:\n",
    "\n",
    "subsidies_matched_all = subsidies_matched_v1.append(subsidies_matched_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results:\n",
    "\n",
    "subsidies_matched_all.to_csv(\"./data/output/all_matches.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# major_league_stadiums = stadiums[stadiums['stadium_sport']!='soccer']\n",
    "# major_league_stadiums[\n",
    "#     ~major_league_stadiums['stadium_id'].isin(subsidies_matched_all[\"stadium_id\"])\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the resulting matches by stadium_id and subsidy record_index: \n",
    "\n",
    "subsidies_by_stadium_record = subsidies_matched_all.groupby(['stadium_id','record_index','year_opened']).agg(\n",
    "    {'total_cost_reported': 'first',\n",
    "     'public_cost_reported': 'first',\n",
    "     'total_cost_2010': 'first',\n",
    "     'public_cost_2010': 'first',\n",
    "     'public_share_pct': 'first'\n",
    "    }\n",
    ")\n",
    "\n",
    "subsidies_by_stadium_record = subsidies_by_stadium_record.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the results by stadium_id and obtain total public costs: \n",
    "\n",
    "subsidies_by_stadium = subsidies_by_stadium_record.groupby(['stadium_id']).agg(\n",
    "        {'public_cost_2010': np.nansum}\n",
    "    )\n",
    "\n",
    "subsidies_by_stadium = subsidies_by_stadium.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mergre the data on total public costs with the initial stadiums table:\n",
    "\n",
    "subsidies_by_stadium = subsidies_by_stadium.merge(stadiums, how = 'left', left_on = 'stadium_id',  right_on = 'stadium_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stadium_id</th>\n",
       "      <th>public_cost_2010</th>\n",
       "      <th>stadium_sport</th>\n",
       "      <th>location_name</th>\n",
       "      <th>city</th>\n",
       "      <th>stadium_cbg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sg:008eedc461cd430f8be8e2450a1f5702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hockey</td>\n",
       "      <td>Verizon Center</td>\n",
       "      <td>washington</td>\n",
       "      <td>110010058002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sg:008eedc461cd430f8be8e2450a1f5702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basketball</td>\n",
       "      <td>Verizon Center</td>\n",
       "      <td>washington</td>\n",
       "      <td>110010058002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sg:022558c60a6b480aaa6bb0e7dadb4e6a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basketball</td>\n",
       "      <td>Bmo Harris Bradley Center</td>\n",
       "      <td>milwaukee</td>\n",
       "      <td>550791863001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sg:082e609ab2c544d6b33bec38563ad068</td>\n",
       "      <td>531.0</td>\n",
       "      <td>basketball</td>\n",
       "      <td>Amway Center</td>\n",
       "      <td>orlando</td>\n",
       "      <td>120950105001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sg:08fa621a2cb740d8a33603438abbd0fc</td>\n",
       "      <td>129.0</td>\n",
       "      <td>hockey</td>\n",
       "      <td>Xcel Energy Center</td>\n",
       "      <td>saint paul</td>\n",
       "      <td>271230342011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            stadium_id  public_cost_2010 stadium_sport  \\\n",
       "0  sg:008eedc461cd430f8be8e2450a1f5702               0.0        hockey   \n",
       "1  sg:008eedc461cd430f8be8e2450a1f5702               0.0    basketball   \n",
       "2  sg:022558c60a6b480aaa6bb0e7dadb4e6a               0.0    basketball   \n",
       "3  sg:082e609ab2c544d6b33bec38563ad068             531.0    basketball   \n",
       "4  sg:08fa621a2cb740d8a33603438abbd0fc             129.0        hockey   \n",
       "\n",
       "               location_name        city   stadium_cbg  \n",
       "0             Verizon Center  washington  110010058002  \n",
       "1             Verizon Center  washington  110010058002  \n",
       "2  Bmo Harris Bradley Center   milwaukee  550791863001  \n",
       "3               Amway Center     orlando  120950105001  \n",
       "4         Xcel Energy Center  saint paul  271230342011  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsidies_by_stadium.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "####################### Part II: Capacity Matching #############################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in capacity data\n",
    "\n",
    "capacity_football_baseball = pd.read_csv(\"./data/wiki/capacity_football_baseball.csv\")\n",
    "capacity_nhl = pd.read_csv(\"./data/wiki/capacity_nhl.csv\")\n",
    "capacity_nba = pd.read_csv(\"./data/wiki/capacity_nba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that outputs candidate matches for each stadium based on stadium name and city name:\n",
    "\n",
    "def findWikiMatches(stadium_dict, \n",
    "                    name_field = 'Stadium', \n",
    "                    city_field = 'City', \n",
    "                    type_field = 'Type', \n",
    "                    capacity_field = 'Capacity',\n",
    "                    data = capacity_data,\n",
    "                    start=None,end=None):\n",
    "    stadium_id = stadium_dict['stadium_id']\n",
    "    city_name = stadium_dict['city']\n",
    "    stadium_name = stadium_dict['location_name']\n",
    "    stadium_sport = stadium_dict['stadium_sport']\n",
    "    sortedResults = sorted(\n",
    "        map(lambda item: {'stadium_id': stadium_id,\n",
    "                         'stadium_name': stadium_name,\n",
    "                         'stadium_city': city_name,\n",
    "                         'stadium_sport': stadium_sport,\n",
    "                         'wiki_name': re.sub('(\\[.*\\])', '', item[name_field]),\n",
    "                         'wiki_city': item[city_field],\n",
    "                         'capacity': int(re.sub('(\\[.*\\])', '',item[capacity_field]).replace(\",\",\"\")),\n",
    "                         'wiki_type': item[type_field],\n",
    "                         'best_city_match_distance': nltk.edit_distance(\n",
    "                             city_name.lower().replace('\\n','').replace('/',''),\n",
    "                             item[city_field].split(',')[0].lower().replace('\\n','').replace('/','')\n",
    "                         ),\n",
    "                         'best_match_distance': nltk.edit_distance(\n",
    "                             stadium_name.lower().replace('\\n','').replace('/',''),\n",
    "                             re.sub('(\\[.*\\])', '', item[name_field]).lower().replace('\\n','')\n",
    "                         )},\n",
    "            data.to_dict('records'),\n",
    "           ), key = lambda item: item['best_city_match_distance'], reverse = False\n",
    "    )\n",
    "    \n",
    "    minCityMatchDistance = sortedResults[0]['best_city_match_distance']\n",
    "    \n",
    "    plausible_matches = [item for item in sortedResults if item['best_match_distance']<3]\n",
    "    if plausible_matches:\n",
    "        return plausible_matches\n",
    "\n",
    "\n",
    "    sortedResultsSimilarCity = sorted(\n",
    "        [item for item in sortedResults if (\n",
    "            item['best_city_match_distance'] <= minCityMatchDistance\n",
    "        )\n",
    "        ],\n",
    "        key = lambda item: item['best_match_distance'], reverse = False\n",
    "    )\n",
    "    if sortedResultsSimilarCity:\n",
    "        if sortedResultsSimilarCity[0]['best_match_distance']<6:\n",
    "            return [sortedResultsSimilarCity[0]]\n",
    "        else:\n",
    "            return sortedResultsSimilarCity[start:end]\n",
    "    else:\n",
    "        return [{'stadium_id': stadium_id,\n",
    "                'stadium_name': stadium_name,\n",
    "                'stadium_city': city_name,\n",
    "                'best_city_match_distance': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain capacity record matches for each sport category:\n",
    "\n",
    "wiki_matches_fb = pd.DataFrame.from_records(\n",
    "    flatten(subsidies_by_stadium[subsidies_by_stadium['stadium_sport'].isin(['football','baseball'])][['stadium_id','location_name','city','stadium_sport']].apply(\n",
    "        lambda x: findWikiMatches(\n",
    "            dict(zip(['stadium_id','location_name','city','stadium_sport'],x))\n",
    "        ), axis=1\n",
    "    ))\n",
    ")\n",
    "\n",
    "wiki_matches_nba = pd.DataFrame.from_records(\n",
    "    flatten(subsidies_by_stadium[subsidies_by_stadium['stadium_sport'].isin(['basketball'])][['stadium_id','location_name','city','stadium_sport']].apply(\n",
    "        lambda x: findWikiMatches(\n",
    "            dict(zip(['stadium_id','location_name','city','stadium_sport'],x)),\n",
    "            city_field = 'Location',\n",
    "            name_field = 'Arena',\n",
    "            type_field = 'Opened',\n",
    "            data = capacity_nba\n",
    "        ), axis=1\n",
    "    ))\n",
    ")\n",
    "\n",
    "wiki_matches_nhl = pd.DataFrame.from_records(\n",
    "    flatten(subsidies_by_stadium[subsidies_by_stadium['stadium_sport'].isin(['hockey'])][['stadium_id','location_name','city','stadium_sport']].apply(\n",
    "        lambda x: findWikiMatches(\n",
    "            dict(zip(['stadium_id','location_name','city','stadium_sport'],x)),\n",
    "            city_field = 'Location',\n",
    "            name_field = 'Arena',\n",
    "            type_field = 'Opened',\n",
    "            data = capacity_nhl\n",
    "        ), axis=1\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output candidate matches to csv for manual review:\n",
    "\n",
    "wiki_matches_fb.to_csv(\"./tmp/wiki_matches_football_baseball.csv\", index=False)\n",
    "wiki_matches_nba.to_csv(\"./tmp/wiki_matches_nba.csv\", index=False)\n",
    "wiki_matches_nhl.to_csv(\"./tmp/wiki_matches_nhl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the manually verified matches:\n",
    "\n",
    "wiki_data = pd.DataFrame()\n",
    "for sport in ['nba','nhl','football_baseball']:\n",
    "    wiki_data = wiki_data.append(pd.read_csv(f\"./data/manual-matches/wiki_matches_{sport}.csv\"))\n",
    "    \n",
    "wiki_data = wiki_data[wiki_data['match']==1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge capacity data with subsidies by stadium table:\n",
    "\n",
    "\n",
    "subsidies_and_capacity_by_stadium = subsidies_by_stadium.merge(\n",
    "    wiki_data, \n",
    "    how = 'left', \n",
    "    left_on = ['stadium_id','stadium_sport'], \n",
    "    right_on = ['stadium_id','stadium_sport'],\n",
    ")[[\n",
    "    'stadium_id',\n",
    "    'public_cost_2010',\n",
    "    'stadium_sport',\n",
    "    'location_name',\n",
    "    'city',\n",
    "    'match',\n",
    "    'wiki_name',\n",
    "    'wiki_city',\n",
    "    'capacity'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data on games:\n",
    "\n",
    "stadiums_games = {}\n",
    "stadiums_games['hockey'] = pd.read_csv(\n",
    "    \"/home/user/projects/stadiums/data/processed/descriptive/hockey_stadiums_summary_2018.csv\"\n",
    ")\n",
    "stadiums_games['basketball'] = pd.read_csv(\n",
    "    \"/home/user/projects/stadiums/data/processed/descriptive/basketball_stadiums_summary_2018.csv\"\n",
    ")\n",
    "stadiums_games['baseball'] = pd.read_csv(\n",
    "    \"/home/user/projects/stadiums/data/processed/descriptive/baseball_stadiums_summary_2018.csv\"\n",
    ")\n",
    "stadiums_games['football'] = pd.read_csv(\n",
    "    \"/home/user/projects/stadiums/data/processed/descriptive/football_stadiums_summary_2018.csv\"\n",
    ")\n",
    "\n",
    "stadiums_games['all'] = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group games data by stadium:\n",
    "\n",
    "for sport in ['hockey','football','basketball','baseball']:\n",
    "    stadiums_games[sport] = stadiums_games[sport].groupby(['stadium_id']).agg({'games': np.sum})\n",
    "    stadiums_games[sport] = stadiums_games[sport].reset_index()\n",
    "    stadiums_games[sport]['stadium_sport'] = sport\n",
    "    stadiums_games['all'] = stadiums_games['all'].append(stadiums_games[sport])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all data on subsidies, capacity and games into the final table 'subsidies_descriptive':\n",
    "\n",
    "subsidies_descriptive = subsidies_and_capacity_by_stadium[\n",
    "    subsidies_and_capacity_by_stadium['stadium_sport']!='soccer'\n",
    "].merge(\n",
    "    stadiums_games['all'], \n",
    "    how = 'inner', \n",
    "    on = ['stadium_id','stadium_sport'])\n",
    "\n",
    "subsidies_descriptive = subsidies_descriptive[subsidies_descriptive['capacity'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "# Number of stadiums in the final table:\n",
    "\n",
    "print(subsidies_descriptive['stadium_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "####################### Part III: Cost-Benefit Analysis ########################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the externality multiplier on additional stadium visits (using the main results in the paper)\n",
    "\n",
    "visits_coef = {\n",
    "    'basketball': 0.1963 + 0.0097,\n",
    "    'baseball': 0.2929 + 0.0648,\n",
    "    'football': 0.3978 + 0.1258,\n",
    "    'hockey': 0.1963 + 0.0097}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define average capacity load on game days by sport, using the data from wiki: \n",
    "# https://en.wikipedia.org/wiki/List_of_attendance_figures_at_domestic_professional_sports_leagues\n",
    "\n",
    "capacity_coef = {'basketball': 0.9406, 'baseball': 0.6647, 'football': 0.9613 , 'hockey': 0.9517}#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dollar per customer value assumed for each business visit, and the intererst rate:\n",
    "\n",
    "individial_monetary_value = 15\n",
    "risk_free_rate = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the above defined estimates to the main table:\n",
    "\n",
    "subsidies_descriptive['visits_coef'] =  subsidies_descriptive['stadium_sport'].map(lambda x: visits_coef[x])\n",
    "subsidies_descriptive['capacity_coef'] =  subsidies_descriptive['stadium_sport'].map(lambda x: capacity_coef[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data on stadium visits on game/no-game days\n",
    "\n",
    "game_days = pd.read_csv('/home/user/projects/stadiums/data/processed/descriptive/stadium_game_no_game_visits.csv')\n",
    "game_days = game_days.pivot(index=['stadium_id','sport'], columns='game', values='stadium_visits')\n",
    "game_days = game_days.reset_index()\n",
    "game_days.columns = ['stadium_id','stadium_sport','visits_nogame','visits_game']\n",
    "\n",
    "# Compute the share of visits on non-game days (as a fraction of the average visits on game days) by stadium:\n",
    "\n",
    "game_days['visits_ng_share'] = game_days['visits_nogame']/game_days['visits_game']\n",
    "game_days = game_days.groupby(['stadium_id']).agg({'visits_ng_share': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the no-game visit shares to the main table:\n",
    "\n",
    "subsidies_descriptive = subsidies_descriptive.merge(game_days, how='left', on='stadium_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to caclulate discounted years to return value:\n",
    "\n",
    "def yearsToReturn(cost,cash_flow,rate):\n",
    "    if rate: \n",
    "        try:\n",
    "            ytr = -1 * (math.log(1 - (cost * rate / cash_flow)))/math.log(1+rate)\n",
    "        except ValueError:\n",
    "            ytr = float('inf')\n",
    "    else:\n",
    "        ytr = cost/cash_flow\n",
    "    return ytr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate annual benefits to the surrounding businesses for each stadium:\n",
    "\n",
    "def calculateBenefits(beta,e_value, games, capacity, capacity_share, no_game_share, no_game_scale):\n",
    "    gameAttendance = (games * capacity *capacity_share)\n",
    "    noGameAttendance = ((365-games) * capacity * capacity_share * no_game_share)\n",
    "    totalAttendance = gameAttendance + noGameAttendance * no_game_scale\n",
    "    return (totalAttendance * beta * e_value / (10.0**6), totalAttendance/(10.0**6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print final summary tables:\n",
    "\n",
    "def printSummary(df, e_value, no_game_scale):\n",
    "    data = df.copy()\n",
    "    data = data[data['public_cost_2010']>0]\n",
    "    data['annual_visits_est'] = data[\n",
    "        [\n",
    "        'visits_coef',\n",
    "        'games',\n",
    "        'capacity',\n",
    "        'capacity_coef',\n",
    "        'visits_ng_share'\n",
    "        ]\n",
    "    ].apply(\n",
    "        lambda x: calculateBenefits(x[0],e_value,x[1],x[2],x[3],x[4],no_game_scale)[1], axis=1\n",
    "    )\n",
    "    data['annual_benefit_est'] = data[\n",
    "        [\n",
    "        'visits_coef',\n",
    "        'games',\n",
    "        'capacity',\n",
    "        'capacity_coef',\n",
    "        'visits_ng_share'\n",
    "        ]\n",
    "    ].apply(\n",
    "        lambda x: calculateBenefits(x[0],e_value,x[1],x[2],x[3],x[4],no_game_scale)[0], axis=1\n",
    "    )\n",
    "    \n",
    "    data = data.groupby(['stadium_id','location_name']).agg({\n",
    "        'stadium_sport': (lambda x: ','.join(x)),\n",
    "        'annual_visits_est': 'sum',\n",
    "        'annual_benefit_est': 'sum',\n",
    "        'public_cost_2010': 'first'\n",
    "    })\n",
    "    data['sport'] = data['stadium_sport'].map(\n",
    "        lambda x: \"hockey or basketball\" if x in ['basketball', 'hockey', 'hockey,basketball'] else x\n",
    "    )\n",
    "    data['years_to_return_nd'] = data[['public_cost_2010','annual_benefit_est']].apply(\n",
    "        lambda x: yearsToReturn(x[0],x[1],0),\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "    data['years_to_return_d'] = data[['public_cost_2010','annual_benefit_est']].apply(\n",
    "        lambda x: yearsToReturn(x[0],x[1],risk_free_rate),\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "    data['npv_30y'] = data[['public_cost_2010','annual_benefit_est']].apply(\n",
    "        lambda x: x[1]*(( 1 - (1 + risk_free_rate) ** (-30) )/risk_free_rate) - x[0],\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "    stats = ['mean', percentile(0.25), percentile(0.50), percentile(0.75)]\n",
    "    variables = [\n",
    "        'annual_visits_est','annual_benefit_est','public_cost_2010',\n",
    "        'npv_30y'\n",
    "    ]\n",
    "    aggfuncs = { v: stats for v in variables }\n",
    "        \n",
    "    summ_all = data.groupby([True]*len(data)).agg(aggfuncs).round(2)\n",
    "\n",
    "    sum_by_sport = data.groupby(['sport']).agg(aggfuncs).round(2)\n",
    "    \n",
    "    res = summ_all.append(sum_by_sport).rename(\n",
    "        columns={\n",
    "            'annual_benefit_est': 'Annual benefits ($M)',\n",
    "            'annual_visits_est': 'Annual attendance (m)',\n",
    "            'public_cost_2010': 'Public costs at 2010 ($M)',\n",
    "            'npv_30y': 'NPV over 30 years ($M)',\n",
    "#             'years_to_return_nd':'Payback period (years, not discounted)',\n",
    "#             'years_to_return_d':'Payback period (years, discounted)',\n",
    "            'percentile_25': 'Q25',\n",
    "            'percentile_50': 'Median',\n",
    "            'percentile_75': 'Q75',\n",
    "            'mean': 'Mean'\n",
    "        }\n",
    "    ).stack(0)[['Mean','Q25','Median','Q75']]\n",
    "    return res\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
