{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################                                                                                                                                                              \n",
    "################################################################################\n",
    "#\n",
    "# FILE: hockey-download.py\n",
    "#\n",
    "# BY: Dmitry Sedov \n",
    "#\n",
    "# CREATED: Tue Apr 14 2020\n",
    "#\n",
    "# DESC: This code downloads data about hockey teams / games from \n",
    "#       https://www.hockey-reference.com\n",
    "#\n",
    "# EXEC:\n",
    "#      \n",
    "################################################################################\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Libraries #####################################\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Constants #####################################\n",
    "\n",
    "main_url = 'https://www.hockey-reference.com'\n",
    "teams_url = 'https://www.hockey-reference.com/teams/'\n",
    "wiki_url = 'https://en.wikipedia.org/wiki/National_Hockey_League'\n",
    "teams_output_folder = '/Users/muser/dfolder/Research/stadiums/data/hockey/teams/'\n",
    "games_output_folder = '/Users/muser/dfolder/Research/stadiums/data/hockey/games/'\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Get list of all teams ################################\n",
    "\n",
    "teams_page = requests.get(teams_url).text\n",
    "teams_soup = BeautifulSoup(teams_page)\n",
    "active_teams_table = teams_soup.find('table', {'id': 'active_franchises'})\n",
    "head = str(active_teams_table.find('thead'))\n",
    "rows = '\\n'.join(str(x) for x in active_teams_table.find_all('tr', {'class': 'full_table'}))\n",
    "active_teams_table = '<table>\\n' + head + '\\n<tbody>\\n' + rows + '\\n</tbody>\\n' + '</table>'\n",
    "active_teams_table = pd.read_html(active_teams_table)\n",
    "active_teams_table = active_teams_table[0]\n",
    "active_teams_table.rename(columns = {'Franchise': 'name'}, inplace = True)\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_teams_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Get links of all teams ###############################\n",
    "\n",
    "teams_soup = BeautifulSoup(teams_page, 'html.parser')\n",
    "active_teams = teams_soup.find('table', {'id': 'active_franchises'})\n",
    "temp = ({'link': tag['href'], \n",
    "         'name': tag.text} for tag in active_teams.find_all('a', \n",
    "                                                            attrs = {'class': None},\n",
    "                                                            href = True))\n",
    "team_links = pd.DataFrame(temp)\n",
    "\n",
    "team_links['link'] = team_links['link'].apply(lambda x: '/'+'/'.join(x.split('/')[1:3]) + '/')\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Merge for a teams dataset ##############################\n",
    "\n",
    "hockey_teams = pd.merge(active_teams_table, \n",
    "                        team_links, \n",
    "                        how = 'outer',\n",
    "                        on = 'name', \n",
    "                        validate = 'one_to_one')\n",
    "\n",
    "# Change links for some teams\n",
    "hockey_teams.loc[hockey_teams['name'] == 'Arizona Coyotes', 'link'] = '/teams/ARI/'\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Function to get the stadium ############################\n",
    "\n",
    "pattern = re.compile(r'Primary Arena')\n",
    "\n",
    "def get_stadium(link, year):\n",
    "    print(link)\n",
    "    team_year_url = main_url + link + str(year) + '.html'\n",
    "    team_year_soup = BeautifulSoup(requests.get(team_year_url).text, \n",
    "                                   'html.parser')\n",
    "    try:\n",
    "        stadium = team_year_soup.find('strong',\n",
    "                                      text = pattern).parent.a.text\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    return stadium\n",
    "    \n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams['stadium_2017'] = hockey_teams.apply(lambda row: get_stadium(row['link'], 2017),\n",
    "                                                  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams['stadium_2018'] = hockey_teams.apply(lambda row: get_stadium(row['link'], 2018),\n",
    "                                                  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams['stadium_2019'] = hockey_teams.apply(lambda row: get_stadium(row['link'], 2019),\n",
    "                                                  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams['stadium_2020'] = hockey_teams.apply(lambda row: get_stadium(row['link'], 2020),\n",
    "                                                  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams['code'] = hockey_teams['link'].apply(lambda x: x.split('/')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams.loc[hockey_teams['name'] == 'Detroit Red Wings', ['stadium_2018', 'stadium_2019', 'stadium_2020']] = 'Little Caesars Arena'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams.to_csv(os.path.join(teams_output_folder, 'hockey_teams.csv'),\n",
    "                    index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Function to get the games ############################\n",
    "\n",
    "def get_games(link, year):\n",
    "    team_code = link.split('/')[2]\n",
    "    print(team_code)\n",
    "    schedule_year_url = main_url + link + str(year) + '_games.html'\n",
    "    try:\n",
    "        schedule_tables = pd.read_html(schedule_year_url)\n",
    "    except HTTPError:\n",
    "        return None\n",
    "    season = schedule_tables[0]\n",
    "    # Filter non-games rows out\n",
    "    mask = season.iloc[:,0].apply(lambda x: x.isdigit())\n",
    "    season_schedule_table = season.loc[mask].copy()\n",
    "    season_schedule_table['team_code'] = team_code\n",
    "    season_schedule_table.to_csv(os.path.join(games_output_folder,\n",
    "                                              str(year),\n",
    "                                              f'{team_code}_season_games.csv'),\n",
    "                                 index = False)\n",
    "    try:\n",
    "        playoff = schedule_tables[1]\n",
    "    except IndexError:\n",
    "        print(f'No playoffs for {team_code}.')\n",
    "        return None\n",
    "    try:\n",
    "        mask = playoff.iloc[:,0].apply(lambda x: x.isdigit())\n",
    "        playoff_schedule_table = playoff.loc[mask].copy()\n",
    "    except AttributeError:\n",
    "        playoff_schedule_table = playoff\n",
    "    playoff_schedule_table['team_code'] = team_code\n",
    "    playoff_schedule_table.to_csv(os.path.join(games_output_folder,\n",
    "                                               str(year),\n",
    "                                               f'{team_code}_playoff_games.csv'), \n",
    "                                  index = False)\n",
    "    return None\n",
    "    \n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams.apply(lambda row: get_games(row['link'], 2017), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams.apply(lambda row: get_games(row['link'], 2018), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams.apply(lambda row: get_games(row['link'], 2019), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams.apply(lambda row: get_games(row['link'], 2020), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the list of the teams locations from Wikipedia\n",
    "wiki_tables = pd.read_html(wiki_url, attrs = {'class': 'wikitable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean table\n",
    "teams_locations = wiki_tables[0].droplevel(1, axis = 1)\n",
    "mask = (teams_locations['Capacity'] != 'Western Conference')\n",
    "teams_locations = teams_locations[mask].sort_values('Team').reset_index(drop = True)\n",
    "teams_locations['Team'] = teams_locations['Team'].apply(lambda x: re.sub('[^a-zA-Z ]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_locations.to_csv(os.path.join(teams_output_folder, \n",
    "                                    'hockey_locations.csv'), \n",
    "                       index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams = pd.read_csv(os.path.join(teams_output_folder, 'hockey_teams.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(hockey_teams, \n",
    "         teams_locations, \n",
    "         how = 'left', \n",
    "         left_on = 'name',\n",
    "         right_on = 'Team', \n",
    "         validate = 'one_to_one').shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
